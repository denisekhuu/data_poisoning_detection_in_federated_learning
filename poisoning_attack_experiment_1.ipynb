{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe4f3d4-0a22-45ee-8666-ecfb51812149",
   "metadata": {
    "id": "1fe4f3d4-0a22-45ee-8666-ecfb51812149"
   },
   "source": [
    "# Poisoning Attack in Federated Learning Experiment 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b86e7b-b36a-4fe9-b461-d5899f4acc84",
   "metadata": {},
   "source": [
    "Purpose: \n",
    "- What is the performance loss induced through the different poisoning attack? \n",
    "- What is the performance of the global model without poisoning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df47ddb-9ac8-4975-bc12-19720b560a88",
   "metadata": {},
   "source": [
    "## Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "M2Vf2Mi6GhEG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2Vf2Mi6GhEG",
    "outputId": "84bd21bc-0d24-421b-feb6-7438264bbf4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.flush_and_unmount()\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rvrHDJ6OGk-c",
   "metadata": {
    "id": "rvrHDJ6OGk-c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks')\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/federated_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9n3fTWy5KXBw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9n3fTWy5KXBw",
    "outputId": "2cf257db-d1e8-45d6-a19c-a8cbafd44fd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.41.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
      "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.21.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e07f7a-47cd-4280-ad8f-9976c9092c31",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466d7488-718e-4275-b3ca-ceb4bfc32f23",
   "metadata": {
    "id": "466d7488-718e-4275-b3ca-ceb4bfc32f23"
   },
   "outputs": [],
   "source": [
    "from federated_learning.utils import SHAPUtil, experiment_util\n",
    "from federated_learning import ClientPlane, Configuration, ObserverConfiguration\n",
    "from federated_learning.server import Server\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350261c-a693-4ee1-aae2-3b1b68addad4",
   "metadata": {
    "id": "3350261c-a693-4ee1-aae2-3b1b68addad4"
   },
   "source": [
    "## Additional Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2cd015-f2b1-4d07-a9c2-ecb49c38db25",
   "metadata": {
    "id": "ef2cd015-f2b1-4d07-a9c2-ecb49c38db25"
   },
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "    def __init__(self, num_p_clients, from_label, to_label, natural_label ):\n",
    "        self.num_p_clients = num_p_clients\n",
    "        self.from_label = from_label\n",
    "        self.to_label = to_label\n",
    "        self.neutral_label = natural_label\n",
    "        self.accuracy = []\n",
    "        self.recall = {}\n",
    "        self.initialize_recall()\n",
    "\n",
    "    def initialize_recall(self):\n",
    "        self.recall[self.from_label] = []\n",
    "        self.recall[self.to_label] = []\n",
    "        self.recall[self.neutral_label] = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6b825-9314-449c-9f7a-8224e57baa31",
   "metadata": {
    "id": "77c6b825-9314-449c-9f7a-8224e57baa31"
   },
   "outputs": [],
   "source": [
    "experiments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53cd9e1-7430-43c1-a6a2-be102463d227",
   "metadata": {
    "id": "e53cd9e1-7430-43c1-a6a2-be102463d227"
   },
   "outputs": [],
   "source": [
    "def add_round_to_experiment(experiment, recall, accuracy, from_label, to_label, neutral_label): \n",
    "    experiment.accuracy.append(accuracy)\n",
    "    experiment.recall[from_label].append(recall[from_label])\n",
    "    experiment.recall[to_label].append(recall[to_label])\n",
    "    experiment.recall[neutral_label].append(recall[neutral_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600156e-91dd-4a11-a8aa-f0efda25abce",
   "metadata": {
    "id": "8600156e-91dd-4a11-a8aa-f0efda25abce",
    "tags": []
   },
   "source": [
    "## MNIST(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf2c6d0-14e1-45e0-902c-b844823597f4",
   "metadata": {
    "id": "caf2c6d0-14e1-45e0-902c-b844823597f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from federated_learning.nets import MNISTCNN\n",
    "from federated_learning.dataset import MNISTDataset\n",
    "import os\n",
    "config = Configuration()\n",
    "config.TEMP = os.path.join('/content/drive/My Drive/Colab Notebooks/temp')\n",
    "config.FMNIST_DATASET_PATH = os.path.join('/content/data/fmnist')\n",
    "config.MNIST_DATASET_PATH = os.path.join('/content/data/mnist')\n",
    "config.CIFAR10_DATASET_PATH = os.path.join('/content/data/cifar10')\n",
    "config.VM_URL = \"none\"\n",
    "config.FROM_LABEL = 5\n",
    "config.TO_LABEL = 4\n",
    "config.POISONED_CLIENTS = 0\n",
    "config.DATA_POISONING_PERCENTAGE = 1\n",
    "config.DATASET = MNISTDataset\n",
    "config.MODELNAME = config.MNIST_NAME\n",
    "config.NETWORK = MNISTCNN\n",
    "observer_config = ObserverConfiguration()\n",
    "observer_config.experiment_type = \"shap_fl_poisoned\"\n",
    "observer_config.experiment_id = 1\n",
    "observer_config.test = False\n",
    "observer_config.datasetObserverConfiguration = \"MNIST\"\n",
    "neutral_label = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ce109f-9cf1-45ef-a893-4ebbe4d8d6a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485,
     "referenced_widgets": [
      "c8d51ca6cccb48c5b031cf337b73bc27",
      "c5f954dc6d0b4743a3752294682851f7",
      "0515c0d035ad4895b5060c760eccb8ff",
      "f43f4eeec1f1461c920cb6ba77c9d6c5",
      "0685bc3738cc4e849e605f88018c6347",
      "54c4352dc73a4d47a5e5cc7a555a499c",
      "7857d8d0e8be422aa0e79b21493e5ebf",
      "724b61c604fc43fcb97169ef9fb51c94",
      "92a442e9ff2045e8bd3430dc8336c2ae",
      "cd26db76486046159e0dbcb03590b858",
      "8a272efbc03d4b7bae0bd2caa04c2470",
      "cfbf0b6eb8754f57a0e5cf88299fb6a0",
      "a47e7995c3034fcfac35736115df1273",
      "a37ac19f555f41bd97c92af42597ef35",
      "1b3908a006ee4717ba1ed93b259e581e",
      "5a2eee34cc44494a905c23f8dc16ad0b",
      "f1e222d11c5142feb554b3f7ae51d6a7",
      "8609d28b25d34a959ff94a80d7824201",
      "340b7b34f11d4d02849f6c6e3905e67b",
      "88ad0b15df11462dae005ef43d3ee1b9",
      "f98b352cee544ae4b7e2bdb3fdb8b07d",
      "fbf3b6a5c5a143c5bd7d14a6b4492f6b",
      "ae1f4496388647bda528ec63550f803a",
      "112085208be44476b52dd0dc24b555f6",
      "dcab59517bbb48738932642301ad09d8",
      "198154b6c83743f796a15f86e5d11bad",
      "d021b33129a34c1a8b17a9b795b470ab",
      "4b2564355c7a41e49df952ad7555034f",
      "30736287326b4409bc9569ae4506b0f6",
      "83b961d96aed41b8b7f56b915c4bae32",
      "a253bc5349fb430c832598353d4efb57",
      "2cbc71d4a1344cb6bb4a94a7977de929",
      "8209bd3602e64bbca3a62142a441fab1",
      "7e96b7f4b1a24745b4a8aebdb82d2890",
      "d77668303f8a45a5b2d7ca68f45503d4",
      "6ffc6a3a8831471794a2b2a07938cb08",
      "a266c0ad795943508b4dcbb32743332e",
      "62ba21ba64b04198a0a7c67bd3dad187",
      "8aed2cfe5ead4b3c86f566bb0bf58601",
      "9f2340c0a3574d9e81c46f41294b4942",
      "d73f27394d234f5b994b336aed3dbb0d",
      "83d097fc90ac4616953719288cea3325",
      "6be50e6e75734cf8a4ce318e3c489be7",
      "c94a0509ec9d4e6f834a8c1c6c0a5c2e"
     ]
    },
    "id": "b4ce109f-9cf1-45ef-a893-4ebbe4d8d6a8",
    "outputId": "d434f4fe-9949-402d-af35-c45b76909f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/data/fmnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d51ca6cccb48c5b031cf337b73bc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/data/fmnist/MNIST/raw/train-images-idx3-ubyte.gz to /content/data/fmnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/data/fmnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbf0b6eb8754f57a0e5cf88299fb6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/data/fmnist/MNIST/raw/train-labels-idx1-ubyte.gz to /content/data/fmnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/data/fmnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1f4496388647bda528ec63550f803a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/data/fmnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/data/fmnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/data/fmnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e96b7f4b1a24745b4a8aebdb82d2890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /content/data/fmnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/data/fmnist/MNIST/raw\n",
      "\n",
      "MNIST training data loaded.\n",
      "MNIST test data loaded.\n"
     ]
    }
   ],
   "source": [
    "data = config.DATASET(config)\n",
    "shap_util = SHAPUtil(data.test_dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca9f211-36c6-49fc-a5ce-bec4420134b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ca9f211-36c6-49fc-a5ce-bec4420134b6",
    "outputId": "312749c2-c535-450f-cdb8-dce0dd390c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create 200 clients with dataset of size 300\n"
     ]
    }
   ],
   "source": [
    "server = Server(config, observer_config,data.train_dataloader, data.test_dataloader, shap_util)\n",
    "client_plane = ClientPlane(config, observer_config, data, shap_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef9ecf-7e5a-4c3d-a06c-64ba662b68bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "2eef9ecf-7e5a-4c3d-a06c-64ba662b68bf",
    "outputId": "543b001d-5003-4bbf-b926-20f0194fc77f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "for num_p_clients in [0, 10, 25, 50,75, 100, 200]:\n",
    "    client_plane.reset_default_client_nets()\n",
    "    server.reset_to_default_net()\n",
    "    client_plane.reset_poisoning_attack()\n",
    "    config.POISONED_CLIENTS = num_p_clients\n",
    "    experiment = Experiment(num_p_clients, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
    "    experiment_util.update_configs(client_plane, server, config, observer_config)\n",
    "    client_plane.poison_clients()\n",
    "    server.test()\n",
    "    recall, precision, accuracy = server.analize_test()\n",
    "    add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
    "    for i in range(200):\n",
    "        experiment_util.set_rounds(client_plane, server, i+1)\n",
    "        experiment_util.run_round(client_plane, server, i+1)\n",
    "        if (i+1)%10 == 0:\n",
    "            server.test()\n",
    "            recall, precision, accuracy = server.analize_test()\n",
    "            add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
    "            print(\"Round {} finished\".format(i+1))\n",
    "    print(experiment.accuracy)\n",
    "    print(experiment.recall[config.FROM_LABEL])\n",
    "    print(experiment.recall[config.TO_LABEL])\n",
    "    print(experiment.recall[natural_label])\n",
    "    experiments.append(copy.deepcopy(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca65987-118d-45df-974e-6d0248b360b0",
   "metadata": {
    "id": "3ca65987-118d-45df-974e-6d0248b360b0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for e in experiments: \n",
    "    print(e.accuracyracy)\n",
    "    print(e.recall[config.FROM_LABEL])\n",
    "    print(e.recall[config.TO_LABEL])\n",
    "    print(e.recall[neutral_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f621ea-1b3a-4c2a-9ad7-03ec54c9ed46",
   "metadata": {
    "id": "a6f621ea-1b3a-4c2a-9ad7-03ec54c9ed46"
   },
   "source": [
    "# Fashion MNIST(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eeb61a0-2d44-4d93-be81-7e23b6fd8d6b",
   "metadata": {
    "id": "0eeb61a0-2d44-4d93-be81-7e23b6fd8d6b"
   },
   "outputs": [],
   "source": [
    "from federated_learning.nets import FMNISTCNN\n",
    "from federated_learning.dataset import FMNISTDataset\n",
    "import os\n",
    "config = Configuration()\n",
    "config.TEMP = os.path.join('/content/drive/My Drive/Colab Notebooks/temp')\n",
    "config.FMNIST_DATASET_PATH = os.path.join('/content/data/fmnist')\n",
    "config.MNIST_DATASET_PATH = os.path.join('/content/data/mnist')\n",
    "config.CIFAR10_DATASET_PATH = os.path.join('/content/data/cifar10')\n",
    "config.VM_URL = \"none\"\n",
    "config.FROM_LABEL = 5\n",
    "config.TO_LABEL = 4\n",
    "config.POISONED_CLIENTS = 0\n",
    "config.DATA_POISONING_PERCENTAGE = 1\n",
    "config.DATASET = FMNISTDataset\n",
    "config.MODELNAME = config.FMNIST_NAME\n",
    "config.NETWORK = FMNISTCNN\n",
    "observer_config = ObserverConfiguration()\n",
    "observer_config.experiment_type = \"shap_fl_poisoned\"\n",
    "observer_config.experiment_id = 1\n",
    "observer_config.test = False\n",
    "observer_config.dataset = \"FMNIST\"\n",
    "neutral_label = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a322c77-87bf-45e1-819e-35c2e5dd799a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a322c77-87bf-45e1-819e-35c2e5dd799a",
    "outputId": "e8148887-37aa-4d1d-c1d5-297e9ee20d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionMnist training data loaded.\n",
      "FashionMnist training data loaded.\n",
      "Create 200 clients with dataset of size 300\n"
     ]
    }
   ],
   "source": [
    "data = config.DATASET(config)\n",
    "shap_util = SHAPUtil(data.test_dataloader) \n",
    "server = Server(config, observer_config,data.train_dataloader, data.test_dataloader, shap_util)\n",
    "client_plane = ClientPlane(config, observer_config, data, shap_util)\n",
    "experiments_fmnist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0091bc85-8f15-465a-87f3-ba7bcebd212b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0091bc85-8f15-465a-87f3-ba7bcebd212b",
    "outputId": "123abe19-b3cb-409b-cea0-dae34910474a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load default model successfully\n",
      "No poisoning due to 0. poisoned clients\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 8182/10000 (82%)\n",
      "\n",
      "Round 10 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8508/10000 (85%)\n",
      "\n",
      "Round 20 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8451/10000 (85%)\n",
      "\n",
      "Round 30 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8635/10000 (86%)\n",
      "\n",
      "Round 40 finished\n",
      "Model aggregation in round 50 was successful\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8595/10000 (86%)\n",
      "\n",
      "Round 50 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8745/10000 (87%)\n",
      "\n",
      "Round 60 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8793/10000 (88%)\n",
      "\n",
      "Round 70 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8812/10000 (88%)\n",
      "\n",
      "Round 80 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8813/10000 (88%)\n",
      "\n",
      "Round 90 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.220859\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.292997\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.415836\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.079920\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.063738\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.293617\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.292480\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.038281\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.265904\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.305139\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.551629\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.176691\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.439572\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.053150\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.271376\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.048816\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.151147\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.140010\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.433642\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.146736\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.560418\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.579962\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.543949\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.497717\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.223815\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.350475\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.122212\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.496926\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.501445\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.453327\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.364676\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.168147\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.407776\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.151387\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.127088\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.065125\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.306528\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.333776\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.270318\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.200659\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.581420\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.142995\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.055136\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.027512\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.061114\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.342483\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.039202\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.348673\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.162104\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.365407\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.102202\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.529262\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.166196\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.148674\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.910053\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.146350\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.325939\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.014767\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.710997\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.577490\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.102860\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.052575\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.261347\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.543473\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.452058\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.238355\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.561845\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 1.284263\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.103058\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.109521\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.413783\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.413979\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.408871\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.279545\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.487150\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.595213\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.516365\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.109388\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.321354\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.491767\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.522831\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.453056\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.239125\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.030397\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.499748\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.153317\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.037225\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.303858\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.246859\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.108440\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.063558\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.591298\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.182290\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.172733\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.442665\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.089197\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.417389\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.621173\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.125240\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.966218\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.142911\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.035587\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.417989\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.556366\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 1.337381\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.108083\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.557695\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.307688\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.061719\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.141496\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.441811\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.384595\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.087711\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.507449\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.543671\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.598104\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.271849\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.783903\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.060642\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.082834\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.098472\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.531875\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.372987\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.163005\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.178860\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.698241\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.432939\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.390376\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.061367\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.281303\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.080090\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.395458\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.175747\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.611810\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.300778\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.244919\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.407809\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.116266\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.334975\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.176207\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.280973\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.280453\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.734197\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.488028\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.583344\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.121578\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 1.009630\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.654647\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.577744\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.420450\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8844/10000 (88%)\n",
      "\n",
      "Round 100 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8870/10000 (89%)\n",
      "\n",
      "Round 110 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8901/10000 (89%)\n",
      "\n",
      "Round 120 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8917/10000 (89%)\n",
      "\n",
      "Round 130 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8943/10000 (89%)\n",
      "\n",
      "Round 140 finished\n",
      "Model aggregation in round 150 was successful\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8924/10000 (89%)\n",
      "\n",
      "Round 150 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8940/10000 (89%)\n",
      "\n",
      "Round 160 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8955/10000 (90%)\n",
      "\n",
      "Round 170 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8947/10000 (89%)\n",
      "\n",
      "Round 180 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8984/10000 (90%)\n",
      "\n",
      "Round 190 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.285346\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.139800\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.201490\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.088973\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.270247\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.317305\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.245825\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.033633\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.406761\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.140059\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.188216\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.272692\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.350323\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.299231\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.266481\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.475437\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.741248\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 1.139240\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.311869\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.135003\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.134518\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.061311\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.607049\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.494452\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.229684\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.085323\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.030667\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.109929\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.244886\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.708629\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.227968\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.094094\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.168438\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.400391\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.175409\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.126910\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.134304\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.217662\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.301167\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.135544\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.268629\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.042234\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.517560\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.257753\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.018532\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.500930\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.500327\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.216004\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.008176\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.465589\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.092966\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.457041\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.402303\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.088144\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.237105\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.100493\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.437120\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.365147\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 1.593141\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.252906\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.573067\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.189718\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.256798\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.038964\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.346956\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.098968\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.238808\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.308655\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.176236\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.562083\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.055319\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 1.003225\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.056045\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.475538\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.114966\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.054584\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.382282\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.079508\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.415046\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.439381\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.120523\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.200783\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.191590\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.261646\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.290621\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.027949\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.157590\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.113646\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.046759\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.806469\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.140449\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.173436\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.258850\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.442389\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.102907\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.305335\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.148096\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.044509\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.429773\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.490057\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.013115\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.528931\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.286952\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.139699\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.318776\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.144558\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.097441\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.362146\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.133276\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.594001\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.451104\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.172413\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.108440\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.768800\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.397110\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.550097\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.280500\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.488657\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.138057\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.066748\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.227887\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.057000\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.076770\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.200838\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.244883\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.211765\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.238751\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.191781\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.065758\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.229189\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.897415\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.205960\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.205615\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.338111\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.370082\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.120096\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.158393\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.302214\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.066949\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.281255\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.387087\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.095110\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.291921\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.123230\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.462988\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.030053\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.071692\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.047515\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.375459\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.038638\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8978/10000 (90%)\n",
      "\n",
      "Round 200 finished\n",
      "[0.1252, 0.8182, 0.8508, 0.8451, 0.8635, 0.8595, 0.8745, 0.8793, 0.8812, 0.8813, 0.8844, 0.887, 0.8901, 0.8917, 0.8943, 0.8924, 0.894, 0.8955, 0.8947, 0.8984, 0.8978]\n",
      "[tensor(0.), tensor(0.8550), tensor(0.9480), tensor(0.9860), tensor(0.9350), tensor(0.9350), tensor(0.9760), tensor(0.9590), tensor(0.9640), tensor(0.9550), tensor(0.9640), tensor(0.9660), tensor(0.9630), tensor(0.9560), tensor(0.9670), tensor(0.9570), tensor(0.9770), tensor(0.9830), tensor(0.9620), tensor(0.9840), tensor(0.9530)]\n",
      "[tensor(0.), tensor(0.6480), tensor(0.7150), tensor(0.8490), tensor(0.8920), tensor(0.6770), tensor(0.7790), tensor(0.8080), tensor(0.7760), tensor(0.8730), tensor(0.7660), tensor(0.7710), tensor(0.8840), tensor(0.8660), tensor(0.9060), tensor(0.7940), tensor(0.8460), tensor(0.8690), tensor(0.7940), tensor(0.8340), tensor(0.8900)]\n",
      "[tensor(0.0280), tensor(0.7660), tensor(0.7240), tensor(0.6540), tensor(0.7310), tensor(0.8890), tensor(0.7840), tensor(0.7270), tensor(0.8770), tensor(0.7250), tensor(0.8620), tensor(0.8650), tensor(0.8270), tensor(0.8030), tensor(0.8180), tensor(0.8550), tensor(0.8840), tensor(0.8580), tensor(0.8620), tensor(0.8630), tensor(0.8100)]\n",
      "Load default model successfully\n",
      "Poison 10/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[125 173 129 167 107   7 194 127  70 106]\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 8182/10000 (82%)\n",
      "\n",
      "Round 10 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8401/10000 (84%)\n",
      "\n",
      "Round 20 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8568/10000 (86%)\n",
      "\n",
      "Round 30 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8678/10000 (87%)\n",
      "\n",
      "Round 40 finished\n",
      "Model aggregation in round 50 was successful\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8645/10000 (86%)\n",
      "\n",
      "Round 50 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8774/10000 (88%)\n",
      "\n",
      "Round 60 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8780/10000 (88%)\n",
      "\n",
      "Round 70 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8819/10000 (88%)\n",
      "\n",
      "Round 80 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8872/10000 (89%)\n",
      "\n",
      "Round 90 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.934156\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.673801\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.299683\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.263027\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.418125\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.167404\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.099076\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.064199\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.045173\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.921487\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.209982\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.184583\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.906277\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.187976\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.499233\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.201287\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.115195\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.544454\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.137107\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.734211\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.351006\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.272316\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.213476\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 1.129548\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.090014\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.485685\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.184070\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.072590\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.222448\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.194666\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.277613\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.378894\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.792354\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.288395\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.146245\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.131543\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.061880\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 1.173585\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.014412\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.069172\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.520886\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.882452\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.140874\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.674722\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.265994\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.659645\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.445878\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.084996\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.051802\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.170174\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.465260\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.545442\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.146446\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.574501\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.525402\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.430202\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.068043\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.270080\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.215672\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.352350\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.275659\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.082399\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.394696\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.104858\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.065143\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.408564\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.200804\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.044031\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.023184\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.319574\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.886141\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.401263\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.253956\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.079028\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.158422\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.291199\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.061729\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.152376\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.092307\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.395852\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.488589\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.073186\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.406885\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.554189\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 1.053799\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.461937\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.346245\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.204555\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.095612\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.200394\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.055809\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 1.749064\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.026998\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.111780\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.097615\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.868529\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.083139\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.277230\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.281615\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.894508\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.292393\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.149650\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.263524\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.225775\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.106141\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.077704\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.353556\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.100712\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.598741\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.592801\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.279395\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.428776\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.091402\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.670143\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.675519\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.147302\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.407710\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.116158\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.178705\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.168954\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.156856\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.110405\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.020250\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.132174\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.006353\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.153213\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.024717\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.285182\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.578484\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.107970\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.246042\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.059710\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.235814\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.047378\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.230005\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.349034\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.476890\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.514202\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.144468\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.524491\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.244732\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.059215\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.059212\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.085427\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.396579\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.088830\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.734015\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.131737\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.254506\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.200800\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8695/10000 (87%)\n",
      "\n",
      "Round 100 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8863/10000 (89%)\n",
      "\n",
      "Round 110 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8861/10000 (89%)\n",
      "\n",
      "Round 120 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8944/10000 (89%)\n",
      "\n",
      "Round 130 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8929/10000 (89%)\n",
      "\n",
      "Round 140 finished\n",
      "Model aggregation in round 150 was successful\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8927/10000 (89%)\n",
      "\n",
      "Round 150 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8949/10000 (89%)\n",
      "\n",
      "Round 160 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8967/10000 (90%)\n",
      "\n",
      "Round 170 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8972/10000 (90%)\n",
      "\n",
      "Round 180 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8938/10000 (89%)\n",
      "\n",
      "Round 190 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.033952\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.174879\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.376996\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.202120\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.037333\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.318830\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.014284\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.060856\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.062949\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 1.107741\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.491426\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.297630\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.349893\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.362446\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.888063\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.344851\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.141256\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.056625\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.139771\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.754203\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.234261\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.298163\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.111195\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.224323\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.424791\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.107682\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.029233\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.069626\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.169922\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.021224\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 2.467188\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.806313\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.244600\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.309083\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.837193\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.672110\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.239020\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.432642\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.133626\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.272404\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.127208\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.106933\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.093252\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.789087\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.105939\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.166050\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.950212\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.190814\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.482532\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.181702\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.212018\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.088938\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.576203\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.427865\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.335406\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.369715\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.464010\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.028251\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.348216\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.048271\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.129327\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.109310\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.309739\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.291601\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.315983\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.112470\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.058058\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.196412\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.237651\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.311197\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.233606\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.543379\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.011775\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.045909\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.359671\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.257174\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.213405\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.086667\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.157669\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.254977\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.037277\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.219010\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.167943\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.113986\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.163041\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.028145\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.156770\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.047910\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.600046\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.058417\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.624802\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.509816\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.314981\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.418542\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.442103\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.346125\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.083851\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.268423\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.571065\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.601045\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.182554\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.492207\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.126582\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.045883\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.767517\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.114947\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.073870\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.579562\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.138306\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.220519\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.370423\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.069053\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.024309\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.016206\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.515215\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.481456\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.184223\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.410968\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.048142\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.113482\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.021878\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.140028\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.208142\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.044604\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.529684\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.020951\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.014073\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.115088\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.064147\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.098549\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.036134\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.124817\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.485978\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.035929\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.169796\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.348811\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.218378\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.213457\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.009656\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.125863\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.537932\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.292694\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.073023\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.391910\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.106079\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.113874\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.384978\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.052217\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.154000\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.231201\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8939/10000 (89%)\n",
      "\n",
      "Round 200 finished\n",
      "[0.1252, 0.8182, 0.8401, 0.8568, 0.8678, 0.8645, 0.8774, 0.878, 0.8819, 0.8872, 0.8695, 0.8863, 0.8861, 0.8944, 0.8929, 0.8927, 0.8949, 0.8967, 0.8972, 0.8938, 0.8939]\n",
      "[tensor(0.), tensor(0.8600), tensor(0.9240), tensor(0.9260), tensor(0.9570), tensor(0.8970), tensor(0.9520), tensor(0.9660), tensor(0.9410), tensor(0.9590), tensor(0.8000), tensor(0.9710), tensor(0.9540), tensor(0.9710), tensor(0.9680), tensor(0.9540), tensor(0.9640), tensor(0.9640), tensor(0.9750), tensor(0.9590), tensor(0.9270)]\n",
      "[tensor(0.), tensor(0.7070), tensor(0.7220), tensor(0.7380), tensor(0.8100), tensor(0.6810), tensor(0.8440), tensor(0.8240), tensor(0.7500), tensor(0.8510), tensor(0.8180), tensor(0.8220), tensor(0.7840), tensor(0.8310), tensor(0.8220), tensor(0.8950), tensor(0.8650), tensor(0.8320), tensor(0.7940), tensor(0.8880), tensor(0.9000)]\n",
      "[tensor(0.0280), tensor(0.7420), tensor(0.8170), tensor(0.7280), tensor(0.7570), tensor(0.8760), tensor(0.8250), tensor(0.8030), tensor(0.8370), tensor(0.7850), tensor(0.7760), tensor(0.8800), tensor(0.8950), tensor(0.8690), tensor(0.8080), tensor(0.7990), tensor(0.8470), tensor(0.8220), tensor(0.8670), tensor(0.8160), tensor(0.8110)]\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "Poison 25/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[170  81   3  20  84 186  44 134 129  37 180  43 175  79  97  59  50 148\n",
      "  57 166  64  92  31 141 161]\n",
      "20/25 clients poisoned\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 8146/10000 (81%)\n",
      "\n",
      "Round 10 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8461/10000 (85%)\n",
      "\n",
      "Round 20 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8569/10000 (86%)\n",
      "\n",
      "Round 30 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8659/10000 (87%)\n",
      "\n",
      "Round 40 finished\n",
      "Model aggregation in round 50 was successful\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8453/10000 (85%)\n",
      "\n",
      "Round 50 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8736/10000 (87%)\n",
      "\n",
      "Round 60 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8736/10000 (87%)\n",
      "\n",
      "Round 70 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8820/10000 (88%)\n",
      "\n",
      "Round 80 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8819/10000 (88%)\n",
      "\n",
      "Round 90 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.095273\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.096954\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.934479\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.309324\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.389692\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.235892\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.166298\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.227416\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.305984\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.303114\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.093012\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.050429\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.370407\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.239595\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.580196\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.476673\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.385196\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.346857\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.279426\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.504784\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.360255\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.232350\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.085271\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.560441\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.396416\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.114186\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.061693\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.032703\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.179358\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.577423\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.451888\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.265422\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.120339\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.005097\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.745799\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.482319\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.654160\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.367737\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.044012\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.520504\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.264944\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.747770\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.265244\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.228916\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.096140\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.318456\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.370291\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.504882\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.293345\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.142959\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.128348\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.181475\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.055925\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.199909\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.019728\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.140015\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.265617\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.214596\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.576474\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.562220\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.111760\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.385400\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.311072\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.191270\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.564322\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.453261\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.181263\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.150044\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.398062\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.285036\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.813568\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.221182\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.163894\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.198777\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.698477\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.237764\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.441075\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.619488\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.678651\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.660854\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.160199\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.153171\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.118438\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.397757\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.312308\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.408845\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.397067\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.707084\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.414026\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.276313\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.098439\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.694277\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.084890\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.022167\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.165105\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.364262\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.291826\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.567224\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.091860\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.300150\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.030176\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.183254\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.995937\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.019722\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.253785\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.931662\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.115103\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.289864\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.577404\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.198686\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.128556\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.060999\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.789890\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.136916\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.633906\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.082757\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.106756\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.297302\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.132344\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.274478\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.425151\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.199460\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.186599\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.901856\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.310611\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.094689\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.444579\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.268842\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.734118\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.421463\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.195895\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.278317\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.816279\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.170536\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.178068\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.130293\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.227976\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.555209\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.287119\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.199784\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.546712\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.334704\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.262097\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.178560\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.052689\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.161524\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.646577\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.240067\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.086976\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.311519\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8839/10000 (88%)\n",
      "\n",
      "Round 100 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8895/10000 (89%)\n",
      "\n",
      "Round 110 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8901/10000 (89%)\n",
      "\n",
      "Round 120 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8924/10000 (89%)\n",
      "\n",
      "Round 130 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8886/10000 (89%)\n",
      "\n",
      "Round 140 finished\n",
      "Model aggregation in round 150 was successful\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8934/10000 (89%)\n",
      "\n",
      "Round 150 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8904/10000 (89%)\n",
      "\n",
      "Round 160 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8880/10000 (89%)\n",
      "\n",
      "Round 170 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8945/10000 (89%)\n",
      "\n",
      "Round 180 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8844/10000 (88%)\n",
      "\n",
      "Round 190 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.310963\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.196978\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.104594\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.471431\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.291297\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.555271\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.322984\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.330073\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.186837\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.355736\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.135412\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.380014\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.525256\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.066956\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.153868\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.056038\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.715149\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.207581\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.290742\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.472654\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.139513\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.181472\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.083371\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.102872\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.213480\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.023492\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.472096\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.035503\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.811051\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.194822\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.088383\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.174879\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.235207\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.011707\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.060157\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.432446\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.153006\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.178693\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.321572\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.024275\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.024501\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.043796\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.160877\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.341557\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.033384\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.578770\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.023683\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.445467\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.497155\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.325655\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.130806\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.068093\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.244998\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.574760\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.332792\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.233430\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.330680\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.355662\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.527743\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.057125\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.313927\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.252830\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.452172\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.415643\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.221895\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.141320\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.003950\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.488491\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.198102\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.113289\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.177411\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.638417\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.149797\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.189762\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.319147\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.163057\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 1.096267\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.070462\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.139636\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.468234\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.241446\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.512430\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.464976\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.705809\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.220602\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.375661\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.153392\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.346388\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.416597\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.130588\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.116515\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.080200\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.124019\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.044587\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.145668\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.015549\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.073533\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.988746\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.468323\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.962155\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.271601\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.438114\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.118466\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.166670\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.097578\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.225725\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.224767\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.423055\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.188224\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.376208\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.321156\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.085172\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.058059\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.204792\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.212487\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.077668\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.073660\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.021177\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.251566\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.303768\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.159591\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.844830\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.081505\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.060797\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.067263\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.125716\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.279699\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.618704\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.324649\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.458433\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.460104\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.236455\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.087803\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.169999\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.086221\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.297633\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.173789\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.251721\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.056215\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.066057\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.341694\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.120018\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.235548\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.568201\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.190236\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.580045\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.686022\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.102162\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.159262\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.382282\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8933/10000 (89%)\n",
      "\n",
      "Round 200 finished\n",
      "[0.1252, 0.8146, 0.8461, 0.8569, 0.8659, 0.8453, 0.8736, 0.8736, 0.882, 0.8819, 0.8839, 0.8895, 0.8901, 0.8924, 0.8886, 0.8934, 0.8904, 0.888, 0.8945, 0.8844, 0.8933]\n",
      "[tensor(0.), tensor(0.7950), tensor(0.8990), tensor(0.9350), tensor(0.9420), tensor(0.6960), tensor(0.8480), tensor(0.8780), tensor(0.9460), tensor(0.9520), tensor(0.9470), tensor(0.9390), tensor(0.9740), tensor(0.9630), tensor(0.9930), tensor(0.9650), tensor(0.9330), tensor(0.9630), tensor(0.9480), tensor(0.9600), tensor(0.9140)]\n",
      "[tensor(0.), tensor(0.8090), tensor(0.8030), tensor(0.7200), tensor(0.8780), tensor(0.8110), tensor(0.8070), tensor(0.8470), tensor(0.8820), tensor(0.8560), tensor(0.9100), tensor(0.8310), tensor(0.8200), tensor(0.8450), tensor(0.7690), tensor(0.8430), tensor(0.8540), tensor(0.6940), tensor(0.8850), tensor(0.9300), tensor(0.8550)]\n",
      "[tensor(0.0280), tensor(0.6160), tensor(0.7830), tensor(0.8550), tensor(0.7660), tensor(0.8110), tensor(0.8470), tensor(0.7430), tensor(0.8000), tensor(0.8380), tensor(0.7730), tensor(0.8250), tensor(0.8660), tensor(0.8460), tensor(0.8320), tensor(0.8390), tensor(0.8740), tensor(0.8830), tensor(0.8450), tensor(0.7160), tensor(0.8180)]\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "Poison 50/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[195 192  46  36  24  17  25 171 188 121  60  18 130  27 144 175   7  67\n",
      " 168  48  63  54  96  14 137  45  57 167  35 198 150  20  77  41 189 114\n",
      " 194 120  13 153 122 138  94  81   6 107  21 151 133 126]\n",
      "20/50 clients poisoned\n",
      "40/50 clients poisoned\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 8238/10000 (82%)\n",
      "\n",
      "Round 10 finished\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 8309/10000 (83%)\n",
      "\n",
      "Round 20 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8526/10000 (85%)\n",
      "\n",
      "Round 30 finished\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 7929/10000 (79%)\n",
      "\n",
      "Round 40 finished\n",
      "Model aggregation in round 50 was successful\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8725/10000 (87%)\n",
      "\n",
      "Round 50 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8733/10000 (87%)\n",
      "\n",
      "Round 60 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8739/10000 (87%)\n",
      "\n",
      "Round 70 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8758/10000 (88%)\n",
      "\n",
      "Round 80 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8816/10000 (88%)\n",
      "\n",
      "Round 90 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.352411\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.106822\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.098758\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.067284\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.201028\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.241865\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.539651\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.115837\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.084886\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.429722\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.302223\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.077876\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.293796\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.192825\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.758630\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.577041\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.168817\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.344323\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.016870\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.674906\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.173991\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.251897\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.312474\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.121703\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.429623\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.038000\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.219428\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.098429\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.188027\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.137284\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.407462\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.325381\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.519950\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.228713\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.063633\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.121272\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.313991\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.054263\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.381480\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.193216\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.802304\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.180194\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.182808\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.101107\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.455370\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.305504\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.086777\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.076282\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 1.236248\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.085097\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.786094\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.124248\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.417736\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.685735\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.237229\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.183685\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.357407\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.269512\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.220767\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.289176\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.304507\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.380059\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.682847\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.285936\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.197552\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.200854\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.635908\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.938037\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.514722\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.150004\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.239370\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.101675\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.341772\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.193736\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.089838\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.602584\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.459044\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.269757\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.453327\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.579380\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.478485\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.105306\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.707962\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.425926\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.271102\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.541600\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.034891\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.259388\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.042312\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.264555\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.207417\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.095211\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.164315\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.363097\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.418935\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.347682\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.153641\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.258868\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.228060\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.450396\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.724499\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.353470\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.319568\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.121566\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.165795\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 1.084283\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.228948\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.537797\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.160563\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.139336\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.048064\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.407153\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.094603\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 1.264051\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.518449\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.665519\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.734536\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 1.157295\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.936201\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.507560\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.080265\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.241367\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.022102\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.170564\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.408100\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 1.339069\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.380880\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.386693\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.770745\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 1.051524\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.216460\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.091887\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.677144\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.147754\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.324431\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.076788\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.765007\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.189871\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.374110\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.034141\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.564962\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.155567\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.085109\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 1.074888\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.967448\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.064467\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.281974\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.181721\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.113830\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.179412\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8853/10000 (89%)\n",
      "\n",
      "Round 100 finished\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 8000/10000 (80%)\n",
      "\n",
      "Round 110 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8840/10000 (88%)\n",
      "\n",
      "Round 120 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8884/10000 (89%)\n",
      "\n",
      "Round 130 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8929/10000 (89%)\n",
      "\n",
      "Round 140 finished\n",
      "Model aggregation in round 150 was successful\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8935/10000 (89%)\n",
      "\n",
      "Round 150 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8937/10000 (89%)\n",
      "\n",
      "Round 160 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8929/10000 (89%)\n",
      "\n",
      "Round 170 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8935/10000 (89%)\n",
      "\n",
      "Round 180 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8968/10000 (90%)\n",
      "\n",
      "Round 190 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.012350\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.249368\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.012383\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.113728\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.064537\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.028002\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.064109\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.329699\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.042627\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.017199\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.412779\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.212264\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.217092\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.358888\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.057786\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.289169\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.034383\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.526100\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.092154\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.099298\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.176583\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.310589\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.088545\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.428825\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.507790\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.091200\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.052791\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.206954\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.188345\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.079181\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.705686\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.093743\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.556099\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.524489\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.386646\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.240887\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.431665\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.359043\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.315533\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.207082\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.026658\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.039067\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.358010\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.541046\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.278828\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.181983\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.096623\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.078142\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.240057\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.218793\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.184621\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.127985\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.548100\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.203286\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.501956\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.175846\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.296291\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.026270\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.075346\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.387498\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.216790\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.183159\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.380039\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.101969\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.101540\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.258119\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.506322\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.479451\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.356153\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.560372\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.558354\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.274333\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.084622\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.346964\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.677950\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.466463\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.318473\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.067060\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.247344\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.427009\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.156285\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.084599\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.459678\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.518424\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.306989\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.527872\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.204390\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.290064\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.347384\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.207205\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.179045\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.260843\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.303577\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.044863\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.198316\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.400401\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.430810\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.268209\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.862489\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.076477\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.050508\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.473109\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.560035\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.216096\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.184021\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.024580\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.355774\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.405773\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.170402\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.159641\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.103935\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.172335\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.906956\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.255940\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.322744\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.666626\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.234380\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.450460\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.406083\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.894077\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.313540\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.135947\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.087544\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.198530\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.280879\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.124841\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.229587\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.149156\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.478880\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.096928\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.296127\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.897625\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.106739\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.141969\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.006788\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.429749\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.412095\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.694828\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.076528\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.706151\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.007845\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.113420\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.066899\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.740542\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.513066\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.881195\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.044284\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.459467\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.178587\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.053678\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8984/10000 (90%)\n",
      "\n",
      "Round 200 finished\n",
      "[0.1252, 0.8238, 0.8309, 0.8526, 0.7929, 0.8725, 0.8733, 0.8739, 0.8758, 0.8816, 0.8853, 0.8, 0.884, 0.8884, 0.8929, 0.8935, 0.8937, 0.8929, 0.8935, 0.8968, 0.8984]\n",
      "[tensor(0.), tensor(0.8660), tensor(0.7420), tensor(0.9590), tensor(0.2400), tensor(0.9220), tensor(0.9500), tensor(0.8720), tensor(0.9250), tensor(0.9580), tensor(0.9680), tensor(0.0460), tensor(0.9670), tensor(0.9630), tensor(0.9670), tensor(0.9600), tensor(0.9670), tensor(0.9740), tensor(0.9230), tensor(0.9610), tensor(0.9760)]\n",
      "[tensor(0.), tensor(0.8020), tensor(0.7940), tensor(0.6960), tensor(0.8090), tensor(0.8220), tensor(0.8320), tensor(0.8580), tensor(0.7720), tensor(0.8200), tensor(0.8720), tensor(0.8360), tensor(0.7950), tensor(0.8770), tensor(0.9040), tensor(0.8760), tensor(0.7920), tensor(0.8600), tensor(0.8110), tensor(0.8760), tensor(0.8220)]\n",
      "[tensor(0.0280), tensor(0.6860), tensor(0.7250), tensor(0.8590), tensor(0.7350), tensor(0.7730), tensor(0.8530), tensor(0.7570), tensor(0.8600), tensor(0.7460), tensor(0.7440), tensor(0.8370), tensor(0.9010), tensor(0.8300), tensor(0.8150), tensor(0.8000), tensor(0.8410), tensor(0.8460), tensor(0.8200), tensor(0.8350), tensor(0.8500)]\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "Poison 75/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[164 192  30  27  76  16 107  79   6   5  63 195 126 125  45  33 173 137\n",
      " 120 111 154  11   0 101 128 118 184  96  15 136 115 103  43 177 176 130\n",
      " 194 140  78 124 114  62  28  98  71 172 139  39  72   7   9  92  53 151\n",
      " 123 116  40  25 197  32  88  49  47  48  10   3 145 142 143  99 199 157\n",
      " 162  21  93]\n",
      "20/75 clients poisoned\n",
      "40/75 clients poisoned\n",
      "60/75 clients poisoned\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 8070/10000 (81%)\n",
      "\n",
      "Round 10 finished\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 7631/10000 (76%)\n",
      "\n",
      "Round 20 finished\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 7638/10000 (76%)\n",
      "\n",
      "Round 30 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8671/10000 (87%)\n",
      "\n",
      "Round 40 finished\n",
      "Model aggregation in round 50 was successful\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8681/10000 (87%)\n",
      "\n",
      "Round 50 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8727/10000 (87%)\n",
      "\n",
      "Round 60 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8723/10000 (87%)\n",
      "\n",
      "Round 70 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8741/10000 (87%)\n",
      "\n",
      "Round 80 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8139/10000 (81%)\n",
      "\n",
      "Round 90 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 1.372598\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.234591\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.508183\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.944464\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.197199\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.667152\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.040584\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.768144\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.296747\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.354566\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.152610\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.714578\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.143367\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.032118\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.043497\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.067937\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.241124\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.564352\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.038182\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.069492\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.945181\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.117390\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.391252\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.961868\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.593150\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.151093\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.366050\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.633165\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.196746\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.805569\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.325191\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.034638\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.929762\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.030078\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.556084\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.981895\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.446136\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.166965\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.242513\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.224217\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.155740\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.153873\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.358782\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 1.411580\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.136705\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.578968\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.367186\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.120320\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.494271\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.139936\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.036268\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.153141\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.538540\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.091644\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.241064\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.084410\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.793927\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.208733\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.308341\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.102292\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 1.093352\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.260813\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.183113\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.058325\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.112838\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.072264\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.581708\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.186301\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.172112\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.575459\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.101580\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.652238\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.199195\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.210805\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.514768\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.517438\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.280028\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.052419\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.623485\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.240271\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.267931\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.463851\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.091650\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.565060\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.327055\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.292867\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.269794\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.057159\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.261321\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.135370\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.136947\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.149747\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.478576\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.461491\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.069550\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.454614\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.193158\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.090658\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.405811\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.192709\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.747738\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.055419\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.200039\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 1.249376\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.299547\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.571606\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.407626\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.131987\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.678915\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.599299\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.279168\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.072369\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.129206\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.374241\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.521864\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.588367\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.359335\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.079586\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.460339\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.257832\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.179717\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.395854\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 1.197516\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.239873\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.507618\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.336768\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.249725\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.508297\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.258646\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.251297\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.521318\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.297003\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.161979\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.353229\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.415431\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.398203\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.988851\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.279657\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.560550\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.319442\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.263983\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.252954\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.530625\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.118062\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.383447\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.376708\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.243692\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.618175\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.209224\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.223170\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 7896/10000 (79%)\n",
      "\n",
      "Round 100 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8865/10000 (89%)\n",
      "\n",
      "Round 110 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8647/10000 (86%)\n",
      "\n",
      "Round 120 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8822/10000 (88%)\n",
      "\n",
      "Round 130 finished\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 7939/10000 (79%)\n",
      "\n",
      "Round 140 finished\n",
      "Model aggregation in round 150 was successful\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8157/10000 (82%)\n",
      "\n",
      "Round 150 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8911/10000 (89%)\n",
      "\n",
      "Round 160 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8076/10000 (81%)\n",
      "\n",
      "Round 170 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8779/10000 (88%)\n",
      "\n",
      "Round 180 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8977/10000 (90%)\n",
      "\n",
      "Round 190 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.100456\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.176357\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.075401\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.146035\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.452702\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.143357\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.105190\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.175050\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.538706\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.230305\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.261715\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.141766\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.461923\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.012212\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.084736\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.292093\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.344746\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.120970\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.343310\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.531475\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.100127\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.475043\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.292145\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.259444\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.080143\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.322660\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.044981\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.618965\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.053631\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.240019\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.286405\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.389153\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.221132\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.157354\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.136561\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.204052\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.107662\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.251316\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.250410\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.035025\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.210223\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.576569\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.591435\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.192441\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.759690\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.366392\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.245524\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.345876\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.882969\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.571797\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.120740\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.882769\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.452928\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.804328\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.042293\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.451584\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.250264\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.209193\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.168272\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.700758\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.015616\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.152529\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.051720\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.071551\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.083887\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.137111\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.118812\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.034781\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.110742\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.127348\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.150580\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.018944\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.260291\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 1.011764\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.349538\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.252919\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.541174\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.595216\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.200594\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.139098\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.019255\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.918454\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.931273\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.605825\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.332706\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.276609\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.082026\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.227392\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.174340\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.375272\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.101180\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.236118\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.629542\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.121533\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.561992\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.675011\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.080850\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.228426\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.385633\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.030998\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.063550\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.243519\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.267651\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.322169\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.318400\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.119484\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.218188\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.581769\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.360645\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.603616\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.059068\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.575419\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.094784\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.029974\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.075920\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.167301\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.301846\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.171133\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.096502\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.093055\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.433757\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.303840\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.127831\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.055111\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.329816\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.269643\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.263400\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.303392\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.213069\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.639866\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.036532\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.257355\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.555790\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.738223\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.154077\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.229123\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.185617\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.519286\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.540498\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.128052\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.177198\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.123685\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.399296\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.101561\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.163486\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.178557\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.784086\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.301486\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.089731\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.099843\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8996/10000 (90%)\n",
      "\n",
      "Round 200 finished\n",
      "[0.1252, 0.807, 0.7631, 0.7638, 0.8671, 0.8681, 0.8727, 0.8723, 0.8741, 0.8139, 0.7896, 0.8865, 0.8647, 0.8822, 0.7939, 0.8157, 0.8911, 0.8076, 0.8779, 0.8977, 0.8996]\n",
      "[tensor(0.), tensor(0.7830), tensor(0.0330), tensor(0.0200), tensor(0.9390), tensor(0.9320), tensor(0.9250), tensor(0.8700), tensor(0.8810), tensor(0.2800), tensor(0.0260), tensor(0.9400), tensor(0.6980), tensor(0.8950), tensor(0.0140), tensor(0.1610), tensor(0.9600), tensor(0.1120), tensor(0.7900), tensor(0.9670), tensor(0.9730)]\n",
      "[tensor(0.), tensor(0.6580), tensor(0.8620), tensor(0.6970), tensor(0.8480), tensor(0.9070), tensor(0.7930), tensor(0.8550), tensor(0.8820), tensor(0.8480), tensor(0.8640), tensor(0.8920), tensor(0.8700), tensor(0.8650), tensor(0.9060), tensor(0.8810), tensor(0.7650), tensor(0.8970), tensor(0.8890), tensor(0.8990), tensor(0.8480)]\n",
      "[tensor(0.0280), tensor(0.6210), tensor(0.7550), tensor(0.7340), tensor(0.8070), tensor(0.7230), tensor(0.8670), tensor(0.8030), tensor(0.7360), tensor(0.8400), tensor(0.8520), tensor(0.8020), tensor(0.8230), tensor(0.8220), tensor(0.8240), tensor(0.8170), tensor(0.8770), tensor(0.8040), tensor(0.8340), tensor(0.7810), tensor(0.8620)]\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "Poison 100/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[ 12  72  43 159  95  45  66 115  36 142  42  88 180 157 127 139 199  41\n",
      " 193  96 185 168 181  19 150  57 176 124  81  90  18 149 110 194  27  76\n",
      " 160 173  64 161 190 188  78  83 137  73  21 133  54 130  49 113  35   4\n",
      " 183  24 154  92 145  56  63 120 132 178  53 123   2 158 184 177 140  23\n",
      " 151  80  47   7 156  60  34 105 197  29 135  10  13  55 121 162  32  40\n",
      " 172  22   3   1  68   5 100 134 138 153]\n",
      "20/100 clients poisoned\n",
      "40/100 clients poisoned\n",
      "60/100 clients poisoned\n",
      "80/100 clients poisoned\n",
      "100/100 clients poisoned\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 7446/10000 (74%)\n",
      "\n",
      "Round 10 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8407/10000 (84%)\n",
      "\n",
      "Round 20 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8530/10000 (85%)\n",
      "\n",
      "Round 30 finished\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 7852/10000 (79%)\n",
      "\n",
      "Round 40 finished\n",
      "Model aggregation in round 50 was successful\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 7770/10000 (78%)\n",
      "\n",
      "Round 50 finished\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 7818/10000 (78%)\n",
      "\n",
      "Round 60 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8667/10000 (87%)\n",
      "\n",
      "Round 70 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8568/10000 (86%)\n",
      "\n",
      "Round 80 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8829/10000 (88%)\n",
      "\n",
      "Round 90 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.475868\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.247635\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.378442\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.297523\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.694307\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.161170\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.082055\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.454367\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 1.001820\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.159209\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.018628\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.237053\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.197878\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.056545\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.196430\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.026655\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.420581\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.522320\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.552097\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.148924\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.224147\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.578600\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.295989\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.469274\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.518584\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.505732\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.443558\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.240748\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.133582\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.430100\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.735044\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.717204\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.368525\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.409125\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.217391\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.122210\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.170062\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.192653\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.604330\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.666734\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.125749\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.213076\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.945099\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.282960\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.113611\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.112439\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 1.392773\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.609572\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.364082\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.202913\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.180100\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.128266\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.174625\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.289390\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.563282\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.120653\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.430624\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.563261\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.540081\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.096649\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.042072\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.172533\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.014767\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.217678\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.264474\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.202086\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.245331\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.161094\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.580070\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.524281\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.208202\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.215250\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.057169\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.537897\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.059848\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.086933\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.317397\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.119360\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.169394\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.107140\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.349166\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.206946\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.319922\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.018962\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.042643\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.704264\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.147051\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.308727\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.284198\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.115667\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.283260\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.230759\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.480138\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.532947\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.510409\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.323121\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.121737\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.051850\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.237740\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.202704\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 1.197980\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.260250\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.429261\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.182352\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.228560\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.076638\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.196594\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.162466\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.925989\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.085291\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.535525\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.274235\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.099158\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.474056\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.327037\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.347141\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.330714\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 1.059805\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.077534\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.803354\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.418155\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.196509\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.718322\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.055980\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.479045\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.242759\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.520435\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.245007\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.064451\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.645113\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.850875\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.273324\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.662306\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.842902\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.103307\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.670142\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.612034\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.536134\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.061139\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.293729\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.496762\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.110709\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.371147\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.227148\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.707442\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.427661\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.434466\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.038031\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.409627\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.639806\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 7995/10000 (80%)\n",
      "\n",
      "Round 100 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8146/10000 (81%)\n",
      "\n",
      "Round 110 finished\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 7901/10000 (79%)\n",
      "\n",
      "Round 120 finished\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 7962/10000 (80%)\n",
      "\n",
      "Round 130 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8865/10000 (89%)\n",
      "\n",
      "Round 140 finished\n",
      "Model aggregation in round 150 was successful\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 7946/10000 (79%)\n",
      "\n",
      "Round 150 finished\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 8169/10000 (82%)\n",
      "\n",
      "Round 160 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8926/10000 (89%)\n",
      "\n",
      "Round 170 finished\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8932/10000 (89%)\n",
      "\n",
      "Round 180 finished\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 8021/10000 (80%)\n",
      "\n",
      "Round 190 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.376002\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.092952\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.075677\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.707696\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.063910\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.162800\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.456009\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.523651\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.335532\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.622211\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.060345\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.753508\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.333110\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.257603\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.087160\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.041373\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.043442\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.465427\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.170595\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.357753\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.502546\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.346890\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.089977\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.417528\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.736139\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.322089\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.567308\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.141434\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.138409\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.440951\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.246106\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.143995\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.165451\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 1.152694\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.293212\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.247069\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.162299\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.610852\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.449630\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.491247\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.152669\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.134407\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.106749\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.604689\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.013724\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.279884\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.089150\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.082274\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.183277\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.157815\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.062972\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.007511\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.081984\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.192199\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.119104\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.112072\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.277339\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.535446\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.209814\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.485873\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.492459\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.063303\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.779762\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.911800\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.341202\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.903256\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.319322\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.351062\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.163705\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.116371\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.321762\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.654532\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.271923\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.252531\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.159917\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.232106\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.156491\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.326117\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.395958\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.072061\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.084020\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.111477\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.384798\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.108043\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.051196\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.251353\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.328739\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.443520\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.281138\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.130065\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.087257\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.080564\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.136694\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.078960\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.429126\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.730729\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.060658\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.596657\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.330832\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.092980\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.052615\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.052271\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.054253\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.756387\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.407937\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.276099\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.136007\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.888404\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.088853\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.586305\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.127173\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.302563\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.182428\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.161644\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.068408\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.063302\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.045183\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.428284\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.082793\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.132348\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 1.336134\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.326839\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.353459\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.115725\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.209721\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.141001\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.615241\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.076947\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.085640\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.407839\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.099072\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.444238\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.428025\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.389622\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.324289\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.059413\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.175018\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.294484\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.378104\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.353972\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.105843\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.108331\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.208735\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.068374\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.255066\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.319354\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.266392\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.125767\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.144381\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.144613\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 8930/10000 (89%)\n",
      "\n",
      "Round 200 finished\n",
      "[0.1252, 0.7446, 0.8407, 0.853, 0.7852, 0.777, 0.7818, 0.8667, 0.8568, 0.8829, 0.7995, 0.8146, 0.7901, 0.7962, 0.8865, 0.7946, 0.8169, 0.8926, 0.8932, 0.8021, 0.893]\n",
      "[tensor(0.), tensor(0.0880), tensor(0.9260), tensor(0.9470), tensor(0.0960), tensor(0.0080), tensor(0.0830), tensor(0.8180), tensor(0.7710), tensor(0.9680), tensor(0.0620), tensor(0.2100), tensor(0.0020), tensor(0.0020), tensor(0.9060), tensor(0.0010), tensor(0.1640), tensor(0.9700), tensor(0.9210), tensor(0.0010), tensor(0.9120)]\n",
      "[tensor(0.), tensor(0.8350), tensor(0.7840), tensor(0.8610), tensor(0.7880), tensor(0.8270), tensor(0.9310), tensor(0.7830), tensor(0.7880), tensor(0.7450), tensor(0.8180), tensor(0.7930), tensor(0.7470), tensor(0.8280), tensor(0.8300), tensor(0.9050), tensor(0.8810), tensor(0.7920), tensor(0.8260), tensor(0.8900), tensor(0.7890)]\n",
      "[tensor(0.0280), tensor(0.7350), tensor(0.8170), tensor(0.6540), tensor(0.8500), tensor(0.7530), tensor(0.7420), tensor(0.8240), tensor(0.8710), tensor(0.8830), tensor(0.8430), tensor(0.8680), tensor(0.8510), tensor(0.8740), tensor(0.8860), tensor(0.8340), tensor(0.8580), tensor(0.8910), tensor(0.8830), tensor(0.8280), tensor(0.8410)]\n",
      "Load default model successfully\n",
      "20/200 clients cleaned\n",
      "40/200 clients cleaned\n",
      "60/200 clients cleaned\n",
      "80/200 clients cleaned\n",
      "100/200 clients cleaned\n",
      "120/200 clients cleaned\n",
      "140/200 clients cleaned\n",
      "160/200 clients cleaned\n",
      "180/200 clients cleaned\n",
      "200/200 clients cleaned\n",
      "Cleaning successfully\n",
      "Poison 200/200 clients\n",
      "Flip 100.0% of the 5 labels to 4\n",
      "[137  13  10  78 109 170  23  61 116  38  73  68  47 196 136 114 148 186\n",
      "  72 173 190 119   5  34 124 198  36 130 163  63 183   6  81 145  11 135\n",
      " 161  65 197 182  56  53  99  37 187 158   2  83   3  92  32 107 185 115\n",
      "  48 105 154 157 103  26 188  97  79 192  15  24 118  21  66  31 195  45\n",
      " 172 199 189 159  64 181  75  44  85 149  14 139  35  50  33  43  30  29\n",
      "  46 128 147 101 167 100  40 141  58  54  62 168  95 174 151 102 120 155\n",
      "  82  49 122 175  84 133 127 162  19   8 146 123  67  17 108  25 193  77\n",
      "   4 104  91 166 153 131 142  27 177  12 110  89  18  22  20 194 150  74\n",
      " 121 126  28 169 179   1  86   9  59  80  98 144 106 113   7 160 164 111\n",
      "  71   0 156 125 176 178 134 191 138  16  52 117  42  76  94 143  55 184\n",
      "  90 152 165  87  69  93  39 129 140 112  41  88  96  57  60  51 132  70\n",
      " 180 171]\n",
      "20/200 clients poisoned\n",
      "40/200 clients poisoned\n",
      "60/200 clients poisoned\n",
      "80/200 clients poisoned\n",
      "100/200 clients poisoned\n",
      "120/200 clients poisoned\n",
      "140/200 clients poisoned\n",
      "160/200 clients poisoned\n",
      "180/200 clients poisoned\n",
      "200/200 clients poisoned\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 7355/10000 (74%)\n",
      "\n",
      "Round 10 finished\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7514/10000 (75%)\n",
      "\n",
      "Round 20 finished\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7678/10000 (77%)\n",
      "\n",
      "Round 30 finished\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7722/10000 (77%)\n",
      "\n",
      "Round 40 finished\n",
      "Model aggregation in round 50 was successful\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7752/10000 (78%)\n",
      "\n",
      "Round 50 finished\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7742/10000 (77%)\n",
      "\n",
      "Round 60 finished\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 7876/10000 (79%)\n",
      "\n",
      "Round 70 finished\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 7854/10000 (79%)\n",
      "\n",
      "Round 80 finished\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7894/10000 (79%)\n",
      "\n",
      "Round 90 finished\n",
      "Model aggregation in round 100 was successful\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.093551\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.285284\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.025559\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.246706\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.404775\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.079302\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.024568\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.726115\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.287575\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.098037\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.040631\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.390578\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.373289\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.778564\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.686916\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.155815\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.615263\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.852326\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.386749\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.762933\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.487844\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.373995\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.420389\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.116662\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.451189\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.174059\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.224737\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.295773\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.111696\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.323920\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.114628\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.363811\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.190091\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.163501\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.158050\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.058631\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.726644\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.358538\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.356198\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.180101\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 1.163494\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.282236\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 1.018413\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.343328\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.101892\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.808458\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.532054\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.741114\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.592545\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.154270\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.557359\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.241532\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.156124\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 1.176467\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.104704\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.685008\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.435961\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 1.091590\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.322015\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.321561\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.516200\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.414852\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.100980\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.909285\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.240822\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.409248\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.857897\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.681989\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.402547\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.151932\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.526234\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.246243\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.093093\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.536700\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.113160\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.449673\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.221132\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.388207\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.313686\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.060451\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.464057\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.283400\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.101751\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.125957\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.104270\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.172898\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.259137\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.252656\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.375116\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.438118\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.294137\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.229529\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.416429\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.281600\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.192863\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.051182\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 0.204227\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.318392\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.318684\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.168347\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.771653\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 1.325284\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.654353\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.725931\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.112158\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.054747\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.053305\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.354693\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.062731\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.425334\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.058424\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.213618\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.671552\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 1.177897\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 1.014642\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.245939\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.200333\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.262425\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.127623\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.420426\n",
      "Train Epoch: 100 [0/300 (0%)]\tLoss: 0.325190\n",
      "Train Epoch: 100 [10/300 (3%)]\tLoss: 0.149741\n",
      "Train Epoch: 100 [20/300 (7%)]\tLoss: 0.327143\n",
      "Train Epoch: 100 [30/300 (10%)]\tLoss: 0.084769\n",
      "Train Epoch: 100 [40/300 (13%)]\tLoss: 0.515806\n",
      "Train Epoch: 100 [50/300 (17%)]\tLoss: 0.377536\n",
      "Train Epoch: 100 [60/300 (20%)]\tLoss: 1.235735\n",
      "Train Epoch: 100 [70/300 (23%)]\tLoss: 0.680175\n",
      "Train Epoch: 100 [80/300 (27%)]\tLoss: 0.439548\n",
      "Train Epoch: 100 [90/300 (30%)]\tLoss: 0.266918\n",
      "Train Epoch: 100 [100/300 (33%)]\tLoss: 0.319906\n",
      "Train Epoch: 100 [110/300 (37%)]\tLoss: 0.257409\n",
      "Train Epoch: 100 [120/300 (40%)]\tLoss: 0.749364\n",
      "Train Epoch: 100 [130/300 (43%)]\tLoss: 0.052942\n",
      "Train Epoch: 100 [140/300 (47%)]\tLoss: 0.427136\n",
      "Train Epoch: 100 [150/300 (50%)]\tLoss: 0.304988\n",
      "Train Epoch: 100 [160/300 (53%)]\tLoss: 0.097009\n",
      "Train Epoch: 100 [170/300 (57%)]\tLoss: 0.387367\n",
      "Train Epoch: 100 [180/300 (60%)]\tLoss: 0.478674\n",
      "Train Epoch: 100 [190/300 (63%)]\tLoss: 0.138152\n",
      "Train Epoch: 100 [200/300 (67%)]\tLoss: 0.022705\n",
      "Train Epoch: 100 [210/300 (70%)]\tLoss: 0.099315\n",
      "Train Epoch: 100 [220/300 (73%)]\tLoss: 0.500025\n",
      "Train Epoch: 100 [230/300 (77%)]\tLoss: 0.650788\n",
      "Train Epoch: 100 [240/300 (80%)]\tLoss: 0.279799\n",
      "Train Epoch: 100 [250/300 (83%)]\tLoss: 0.994515\n",
      "Train Epoch: 100 [260/300 (87%)]\tLoss: 0.020608\n",
      "Train Epoch: 100 [270/300 (90%)]\tLoss: 0.130095\n",
      "Train Epoch: 100 [280/300 (93%)]\tLoss: 0.170190\n",
      "Train Epoch: 100 [290/300 (97%)]\tLoss: 0.128670\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7930/10000 (79%)\n",
      "\n",
      "Round 100 finished\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 7897/10000 (79%)\n",
      "\n",
      "Round 110 finished\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 7917/10000 (79%)\n",
      "\n",
      "Round 120 finished\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7950/10000 (80%)\n",
      "\n",
      "Round 130 finished\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 7951/10000 (80%)\n",
      "\n",
      "Round 140 finished\n",
      "Model aggregation in round 150 was successful\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 7981/10000 (80%)\n",
      "\n",
      "Round 150 finished\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 7978/10000 (80%)\n",
      "\n",
      "Round 160 finished\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 8004/10000 (80%)\n",
      "\n",
      "Round 170 finished\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 7992/10000 (80%)\n",
      "\n",
      "Round 180 finished\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 7979/10000 (80%)\n",
      "\n",
      "Round 190 finished\n",
      "Model aggregation in round 200 was successful\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.335750\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.544848\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.064166\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.327894\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.491468\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.346399\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.916514\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.348241\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.096964\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.472610\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.240118\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.151764\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.298424\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.309213\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.246991\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.261144\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.519184\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.098924\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.253547\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.159289\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.254395\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.638450\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.410164\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.173531\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.256716\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.440175\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.551336\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.429374\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.054808\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.293531\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.170676\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.706581\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.140908\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.374342\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.519134\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.166633\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.208582\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.276023\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.174575\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 1.196180\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.059676\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.067245\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.489830\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.581998\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.344938\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.114718\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.112031\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.581130\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.094344\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.366112\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.165886\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.631521\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.065061\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.193121\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.418997\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.511880\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.272617\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.283564\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.427448\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.388136\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.569243\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.184370\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.168450\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.082844\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.183905\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.351910\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.180886\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.942023\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.184297\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.235668\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.039286\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.153566\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.618409\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.173825\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.304900\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.101299\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.491482\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.360811\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.154960\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.111643\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.141033\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.066042\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.062575\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.370004\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.080475\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.113633\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.087572\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.189191\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.415325\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.083917\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.159926\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.399121\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.210446\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.109664\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.015118\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.126235\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.262551\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.260237\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.117242\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.804545\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.019974\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.523882\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.117047\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.099875\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.128606\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.214984\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.145942\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.039098\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.041363\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.284656\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.240848\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.150769\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.403882\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.442297\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.420022\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.350813\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.747930\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.023320\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.048460\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.162949\n",
      "Train Epoch: 200 [0/300 (0%)]\tLoss: 0.774723\n",
      "Train Epoch: 200 [10/300 (3%)]\tLoss: 0.241167\n",
      "Train Epoch: 200 [20/300 (7%)]\tLoss: 0.264408\n",
      "Train Epoch: 200 [30/300 (10%)]\tLoss: 0.110030\n",
      "Train Epoch: 200 [40/300 (13%)]\tLoss: 0.362406\n",
      "Train Epoch: 200 [50/300 (17%)]\tLoss: 0.416694\n",
      "Train Epoch: 200 [60/300 (20%)]\tLoss: 0.055617\n",
      "Train Epoch: 200 [70/300 (23%)]\tLoss: 0.246382\n",
      "Train Epoch: 200 [80/300 (27%)]\tLoss: 0.121151\n",
      "Train Epoch: 200 [90/300 (30%)]\tLoss: 0.031474\n",
      "Train Epoch: 200 [100/300 (33%)]\tLoss: 0.251564\n",
      "Train Epoch: 200 [110/300 (37%)]\tLoss: 0.448660\n",
      "Train Epoch: 200 [120/300 (40%)]\tLoss: 0.096705\n",
      "Train Epoch: 200 [130/300 (43%)]\tLoss: 0.183460\n",
      "Train Epoch: 200 [140/300 (47%)]\tLoss: 0.015668\n",
      "Train Epoch: 200 [150/300 (50%)]\tLoss: 0.404414\n",
      "Train Epoch: 200 [160/300 (53%)]\tLoss: 0.402526\n",
      "Train Epoch: 200 [170/300 (57%)]\tLoss: 0.214445\n",
      "Train Epoch: 200 [180/300 (60%)]\tLoss: 0.026734\n",
      "Train Epoch: 200 [190/300 (63%)]\tLoss: 0.092715\n",
      "Train Epoch: 200 [200/300 (67%)]\tLoss: 0.149050\n",
      "Train Epoch: 200 [210/300 (70%)]\tLoss: 0.291635\n",
      "Train Epoch: 200 [220/300 (73%)]\tLoss: 0.031396\n",
      "Train Epoch: 200 [230/300 (77%)]\tLoss: 0.804480\n",
      "Train Epoch: 200 [240/300 (80%)]\tLoss: 0.185106\n",
      "Train Epoch: 200 [250/300 (83%)]\tLoss: 0.095600\n",
      "Train Epoch: 200 [260/300 (87%)]\tLoss: 0.272576\n",
      "Train Epoch: 200 [270/300 (90%)]\tLoss: 0.371779\n",
      "Train Epoch: 200 [280/300 (93%)]\tLoss: 0.358999\n",
      "Train Epoch: 200 [290/300 (97%)]\tLoss: 0.200954\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 8010/10000 (80%)\n",
      "\n",
      "Round 200 finished\n",
      "[0.1252, 0.7355, 0.7514, 0.7678, 0.7722, 0.7752, 0.7742, 0.7876, 0.7854, 0.7894, 0.793, 0.7897, 0.7917, 0.795, 0.7951, 0.7981, 0.7978, 0.8004, 0.7992, 0.7979, 0.801]\n",
      "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
      "[tensor(0.), tensor(0.7680), tensor(0.8720), tensor(0.7320), tensor(0.7980), tensor(0.6870), tensor(0.9220), tensor(0.8320), tensor(0.8120), tensor(0.7560), tensor(0.8630), tensor(0.7420), tensor(0.7570), tensor(0.8300), tensor(0.7980), tensor(0.8390), tensor(0.8680), tensor(0.8060), tensor(0.8420), tensor(0.8720), tensor(0.8870)]\n",
      "[tensor(0.0280), tensor(0.6320), tensor(0.7010), tensor(0.8090), tensor(0.8280), tensor(0.8220), tensor(0.7370), tensor(0.8060), tensor(0.7930), tensor(0.8680), tensor(0.8010), tensor(0.8830), tensor(0.9060), tensor(0.8880), tensor(0.8710), tensor(0.8020), tensor(0.8510), tensor(0.8720), tensor(0.8570), tensor(0.8530), tensor(0.8440)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "for num_p_clients in [0, 10, 25, 50, 75, 100, 200]:\n",
    "    client_plane.reset_default_client_nets()\n",
    "    server.reset_to_default_net()\n",
    "    client_plane.reset_poisoning_attack()\n",
    "    config.POISONED_CLIENTS = num_p_clients\n",
    "    experiment = Experiment(num_p_clients, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
    "    experiment_util.update_configs(client_plane, server, config, observer_config)\n",
    "    client_plane.poison_clients()\n",
    "    server.test()\n",
    "    recall, precision, accuracy = server.analize_test()\n",
    "    add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
    "    for i in range(200):\n",
    "        experiment_util.set_rounds(client_plane, server, i+1)\n",
    "        experiment_util.run_round(client_plane, server, i+1)\n",
    "        if (i+1)%10 == 0:\n",
    "            server.test()\n",
    "            recall, precision, accuracy = server.analize_test()\n",
    "            add_round_to_experiment(experiment, recall, accuracy, config.FROM_LABEL, config.TO_LABEL, neutral_label)\n",
    "            print(\"Round {} finished\".format(i+1))\n",
    "    print(experiment.accuracy)\n",
    "    print(experiment.recall[config.FROM_LABEL])\n",
    "    print(experiment.recall[config.TO_LABEL])\n",
    "    print(experiment.recall[neutral_label])\n",
    "    experiments_fmnist.append(copy.deepcopy(experiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nEDE6loTZf97",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEDE6loTZf97",
    "outputId": "56ab9697-8eba-4f85-9b18-aae195347d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1252, 0.8182, 0.8508, 0.8451, 0.8635, 0.8595, 0.8745, 0.8793, 0.8812, 0.8813, 0.8844, 0.887, 0.8901, 0.8917, 0.8943, 0.8924, 0.894, 0.8955, 0.8947, 0.8984, 0.8978]\n",
      "[tensor(0.), tensor(0.8550), tensor(0.9480), tensor(0.9860), tensor(0.9350), tensor(0.9350), tensor(0.9760), tensor(0.9590), tensor(0.9640), tensor(0.9550), tensor(0.9640), tensor(0.9660), tensor(0.9630), tensor(0.9560), tensor(0.9670), tensor(0.9570), tensor(0.9770), tensor(0.9830), tensor(0.9620), tensor(0.9840), tensor(0.9530)]\n",
      "[tensor(0.), tensor(0.6480), tensor(0.7150), tensor(0.8490), tensor(0.8920), tensor(0.6770), tensor(0.7790), tensor(0.8080), tensor(0.7760), tensor(0.8730), tensor(0.7660), tensor(0.7710), tensor(0.8840), tensor(0.8660), tensor(0.9060), tensor(0.7940), tensor(0.8460), tensor(0.8690), tensor(0.7940), tensor(0.8340), tensor(0.8900)]\n",
      "[tensor(0.0280), tensor(0.7660), tensor(0.7240), tensor(0.6540), tensor(0.7310), tensor(0.8890), tensor(0.7840), tensor(0.7270), tensor(0.8770), tensor(0.7250), tensor(0.8620), tensor(0.8650), tensor(0.8270), tensor(0.8030), tensor(0.8180), tensor(0.8550), tensor(0.8840), tensor(0.8580), tensor(0.8620), tensor(0.8630), tensor(0.8100)]\n",
      "[0.1252, 0.8182, 0.8401, 0.8568, 0.8678, 0.8645, 0.8774, 0.878, 0.8819, 0.8872, 0.8695, 0.8863, 0.8861, 0.8944, 0.8929, 0.8927, 0.8949, 0.8967, 0.8972, 0.8938, 0.8939]\n",
      "[tensor(0.), tensor(0.8600), tensor(0.9240), tensor(0.9260), tensor(0.9570), tensor(0.8970), tensor(0.9520), tensor(0.9660), tensor(0.9410), tensor(0.9590), tensor(0.8000), tensor(0.9710), tensor(0.9540), tensor(0.9710), tensor(0.9680), tensor(0.9540), tensor(0.9640), tensor(0.9640), tensor(0.9750), tensor(0.9590), tensor(0.9270)]\n",
      "[tensor(0.), tensor(0.7070), tensor(0.7220), tensor(0.7380), tensor(0.8100), tensor(0.6810), tensor(0.8440), tensor(0.8240), tensor(0.7500), tensor(0.8510), tensor(0.8180), tensor(0.8220), tensor(0.7840), tensor(0.8310), tensor(0.8220), tensor(0.8950), tensor(0.8650), tensor(0.8320), tensor(0.7940), tensor(0.8880), tensor(0.9000)]\n",
      "[tensor(0.0280), tensor(0.7420), tensor(0.8170), tensor(0.7280), tensor(0.7570), tensor(0.8760), tensor(0.8250), tensor(0.8030), tensor(0.8370), tensor(0.7850), tensor(0.7760), tensor(0.8800), tensor(0.8950), tensor(0.8690), tensor(0.8080), tensor(0.7990), tensor(0.8470), tensor(0.8220), tensor(0.8670), tensor(0.8160), tensor(0.8110)]\n",
      "[0.1252, 0.8146, 0.8461, 0.8569, 0.8659, 0.8453, 0.8736, 0.8736, 0.882, 0.8819, 0.8839, 0.8895, 0.8901, 0.8924, 0.8886, 0.8934, 0.8904, 0.888, 0.8945, 0.8844, 0.8933]\n",
      "[tensor(0.), tensor(0.7950), tensor(0.8990), tensor(0.9350), tensor(0.9420), tensor(0.6960), tensor(0.8480), tensor(0.8780), tensor(0.9460), tensor(0.9520), tensor(0.9470), tensor(0.9390), tensor(0.9740), tensor(0.9630), tensor(0.9930), tensor(0.9650), tensor(0.9330), tensor(0.9630), tensor(0.9480), tensor(0.9600), tensor(0.9140)]\n",
      "[tensor(0.), tensor(0.8090), tensor(0.8030), tensor(0.7200), tensor(0.8780), tensor(0.8110), tensor(0.8070), tensor(0.8470), tensor(0.8820), tensor(0.8560), tensor(0.9100), tensor(0.8310), tensor(0.8200), tensor(0.8450), tensor(0.7690), tensor(0.8430), tensor(0.8540), tensor(0.6940), tensor(0.8850), tensor(0.9300), tensor(0.8550)]\n",
      "[tensor(0.0280), tensor(0.6160), tensor(0.7830), tensor(0.8550), tensor(0.7660), tensor(0.8110), tensor(0.8470), tensor(0.7430), tensor(0.8000), tensor(0.8380), tensor(0.7730), tensor(0.8250), tensor(0.8660), tensor(0.8460), tensor(0.8320), tensor(0.8390), tensor(0.8740), tensor(0.8830), tensor(0.8450), tensor(0.7160), tensor(0.8180)]\n",
      "[0.1252, 0.8238, 0.8309, 0.8526, 0.7929, 0.8725, 0.8733, 0.8739, 0.8758, 0.8816, 0.8853, 0.8, 0.884, 0.8884, 0.8929, 0.8935, 0.8937, 0.8929, 0.8935, 0.8968, 0.8984]\n",
      "[tensor(0.), tensor(0.8660), tensor(0.7420), tensor(0.9590), tensor(0.2400), tensor(0.9220), tensor(0.9500), tensor(0.8720), tensor(0.9250), tensor(0.9580), tensor(0.9680), tensor(0.0460), tensor(0.9670), tensor(0.9630), tensor(0.9670), tensor(0.9600), tensor(0.9670), tensor(0.9740), tensor(0.9230), tensor(0.9610), tensor(0.9760)]\n",
      "[tensor(0.), tensor(0.8020), tensor(0.7940), tensor(0.6960), tensor(0.8090), tensor(0.8220), tensor(0.8320), tensor(0.8580), tensor(0.7720), tensor(0.8200), tensor(0.8720), tensor(0.8360), tensor(0.7950), tensor(0.8770), tensor(0.9040), tensor(0.8760), tensor(0.7920), tensor(0.8600), tensor(0.8110), tensor(0.8760), tensor(0.8220)]\n",
      "[tensor(0.0280), tensor(0.6860), tensor(0.7250), tensor(0.8590), tensor(0.7350), tensor(0.7730), tensor(0.8530), tensor(0.7570), tensor(0.8600), tensor(0.7460), tensor(0.7440), tensor(0.8370), tensor(0.9010), tensor(0.8300), tensor(0.8150), tensor(0.8000), tensor(0.8410), tensor(0.8460), tensor(0.8200), tensor(0.8350), tensor(0.8500)]\n",
      "[0.1252, 0.807, 0.7631, 0.7638, 0.8671, 0.8681, 0.8727, 0.8723, 0.8741, 0.8139, 0.7896, 0.8865, 0.8647, 0.8822, 0.7939, 0.8157, 0.8911, 0.8076, 0.8779, 0.8977, 0.8996]\n",
      "[tensor(0.), tensor(0.7830), tensor(0.0330), tensor(0.0200), tensor(0.9390), tensor(0.9320), tensor(0.9250), tensor(0.8700), tensor(0.8810), tensor(0.2800), tensor(0.0260), tensor(0.9400), tensor(0.6980), tensor(0.8950), tensor(0.0140), tensor(0.1610), tensor(0.9600), tensor(0.1120), tensor(0.7900), tensor(0.9670), tensor(0.9730)]\n",
      "[tensor(0.), tensor(0.6580), tensor(0.8620), tensor(0.6970), tensor(0.8480), tensor(0.9070), tensor(0.7930), tensor(0.8550), tensor(0.8820), tensor(0.8480), tensor(0.8640), tensor(0.8920), tensor(0.8700), tensor(0.8650), tensor(0.9060), tensor(0.8810), tensor(0.7650), tensor(0.8970), tensor(0.8890), tensor(0.8990), tensor(0.8480)]\n",
      "[tensor(0.0280), tensor(0.6210), tensor(0.7550), tensor(0.7340), tensor(0.8070), tensor(0.7230), tensor(0.8670), tensor(0.8030), tensor(0.7360), tensor(0.8400), tensor(0.8520), tensor(0.8020), tensor(0.8230), tensor(0.8220), tensor(0.8240), tensor(0.8170), tensor(0.8770), tensor(0.8040), tensor(0.8340), tensor(0.7810), tensor(0.8620)]\n",
      "[0.1252, 0.7446, 0.8407, 0.853, 0.7852, 0.777, 0.7818, 0.8667, 0.8568, 0.8829, 0.7995, 0.8146, 0.7901, 0.7962, 0.8865, 0.7946, 0.8169, 0.8926, 0.8932, 0.8021, 0.893]\n",
      "[tensor(0.), tensor(0.0880), tensor(0.9260), tensor(0.9470), tensor(0.0960), tensor(0.0080), tensor(0.0830), tensor(0.8180), tensor(0.7710), tensor(0.9680), tensor(0.0620), tensor(0.2100), tensor(0.0020), tensor(0.0020), tensor(0.9060), tensor(0.0010), tensor(0.1640), tensor(0.9700), tensor(0.9210), tensor(0.0010), tensor(0.9120)]\n",
      "[tensor(0.), tensor(0.8350), tensor(0.7840), tensor(0.8610), tensor(0.7880), tensor(0.8270), tensor(0.9310), tensor(0.7830), tensor(0.7880), tensor(0.7450), tensor(0.8180), tensor(0.7930), tensor(0.7470), tensor(0.8280), tensor(0.8300), tensor(0.9050), tensor(0.8810), tensor(0.7920), tensor(0.8260), tensor(0.8900), tensor(0.7890)]\n",
      "[tensor(0.0280), tensor(0.7350), tensor(0.8170), tensor(0.6540), tensor(0.8500), tensor(0.7530), tensor(0.7420), tensor(0.8240), tensor(0.8710), tensor(0.8830), tensor(0.8430), tensor(0.8680), tensor(0.8510), tensor(0.8740), tensor(0.8860), tensor(0.8340), tensor(0.8580), tensor(0.8910), tensor(0.8830), tensor(0.8280), tensor(0.8410)]\n",
      "[0.1252, 0.7355, 0.7514, 0.7678, 0.7722, 0.7752, 0.7742, 0.7876, 0.7854, 0.7894, 0.793, 0.7897, 0.7917, 0.795, 0.7951, 0.7981, 0.7978, 0.8004, 0.7992, 0.7979, 0.801]\n",
      "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
      "[tensor(0.), tensor(0.7680), tensor(0.8720), tensor(0.7320), tensor(0.7980), tensor(0.6870), tensor(0.9220), tensor(0.8320), tensor(0.8120), tensor(0.7560), tensor(0.8630), tensor(0.7420), tensor(0.7570), tensor(0.8300), tensor(0.7980), tensor(0.8390), tensor(0.8680), tensor(0.8060), tensor(0.8420), tensor(0.8720), tensor(0.8870)]\n",
      "[tensor(0.0280), tensor(0.6320), tensor(0.7010), tensor(0.8090), tensor(0.8280), tensor(0.8220), tensor(0.7370), tensor(0.8060), tensor(0.7930), tensor(0.8680), tensor(0.8010), tensor(0.8830), tensor(0.9060), tensor(0.8880), tensor(0.8710), tensor(0.8020), tensor(0.8510), tensor(0.8720), tensor(0.8570), tensor(0.8530), tensor(0.8440)]\n"
     ]
    }
   ],
   "source": [
    "for e in experiments_fmnist: \n",
    "    print(e.accuracy)\n",
    "    print(e.recall[config.FROM_LABEL])\n",
    "    print(e.recall[config.TO_LABEL])\n",
    "    print(e.recall[neutral_label])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "poisoning_attack_experiment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0515c0d035ad4895b5060c760eccb8ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_724b61c604fc43fcb97169ef9fb51c94",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92a442e9ff2045e8bd3430dc8336c2ae",
      "value": 9912422
     }
    },
    "0685bc3738cc4e849e605f88018c6347": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "112085208be44476b52dd0dc24b555f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b2564355c7a41e49df952ad7555034f",
      "placeholder": "​",
      "style": "IPY_MODEL_30736287326b4409bc9569ae4506b0f6",
      "value": ""
     }
    },
    "198154b6c83743f796a15f86e5d11bad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cbc71d4a1344cb6bb4a94a7977de929",
      "placeholder": "​",
      "style": "IPY_MODEL_8209bd3602e64bbca3a62142a441fab1",
      "value": " 1649664/? [00:00&lt;00:00, 5380394.48it/s]"
     }
    },
    "1b3908a006ee4717ba1ed93b259e581e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f98b352cee544ae4b7e2bdb3fdb8b07d",
      "placeholder": "​",
      "style": "IPY_MODEL_fbf3b6a5c5a143c5bd7d14a6b4492f6b",
      "value": " 29696/? [00:00&lt;00:00, 537072.31it/s]"
     }
    },
    "2cbc71d4a1344cb6bb4a94a7977de929": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30736287326b4409bc9569ae4506b0f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "340b7b34f11d4d02849f6c6e3905e67b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b2564355c7a41e49df952ad7555034f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54c4352dc73a4d47a5e5cc7a555a499c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a2eee34cc44494a905c23f8dc16ad0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62ba21ba64b04198a0a7c67bd3dad187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6be50e6e75734cf8a4ce318e3c489be7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ffc6a3a8831471794a2b2a07938cb08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d73f27394d234f5b994b336aed3dbb0d",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83d097fc90ac4616953719288cea3325",
      "value": 4542
     }
    },
    "724b61c604fc43fcb97169ef9fb51c94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7857d8d0e8be422aa0e79b21493e5ebf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e96b7f4b1a24745b4a8aebdb82d2890": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d77668303f8a45a5b2d7ca68f45503d4",
       "IPY_MODEL_6ffc6a3a8831471794a2b2a07938cb08",
       "IPY_MODEL_a266c0ad795943508b4dcbb32743332e"
      ],
      "layout": "IPY_MODEL_62ba21ba64b04198a0a7c67bd3dad187"
     }
    },
    "8209bd3602e64bbca3a62142a441fab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83b961d96aed41b8b7f56b915c4bae32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83d097fc90ac4616953719288cea3325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8609d28b25d34a959ff94a80d7824201": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88ad0b15df11462dae005ef43d3ee1b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a272efbc03d4b7bae0bd2caa04c2470": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8aed2cfe5ead4b3c86f566bb0bf58601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92a442e9ff2045e8bd3430dc8336c2ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f2340c0a3574d9e81c46f41294b4942": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a253bc5349fb430c832598353d4efb57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a266c0ad795943508b4dcbb32743332e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6be50e6e75734cf8a4ce318e3c489be7",
      "placeholder": "​",
      "style": "IPY_MODEL_c94a0509ec9d4e6f834a8c1c6c0a5c2e",
      "value": " 5120/? [00:00&lt;00:00, 152758.83it/s]"
     }
    },
    "a37ac19f555f41bd97c92af42597ef35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_340b7b34f11d4d02849f6c6e3905e67b",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88ad0b15df11462dae005ef43d3ee1b9",
      "value": 28881
     }
    },
    "a47e7995c3034fcfac35736115df1273": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1e222d11c5142feb554b3f7ae51d6a7",
      "placeholder": "​",
      "style": "IPY_MODEL_8609d28b25d34a959ff94a80d7824201",
      "value": ""
     }
    },
    "ae1f4496388647bda528ec63550f803a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_112085208be44476b52dd0dc24b555f6",
       "IPY_MODEL_dcab59517bbb48738932642301ad09d8",
       "IPY_MODEL_198154b6c83743f796a15f86e5d11bad"
      ],
      "layout": "IPY_MODEL_d021b33129a34c1a8b17a9b795b470ab"
     }
    },
    "c5f954dc6d0b4743a3752294682851f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54c4352dc73a4d47a5e5cc7a555a499c",
      "placeholder": "​",
      "style": "IPY_MODEL_7857d8d0e8be422aa0e79b21493e5ebf",
      "value": ""
     }
    },
    "c8d51ca6cccb48c5b031cf337b73bc27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5f954dc6d0b4743a3752294682851f7",
       "IPY_MODEL_0515c0d035ad4895b5060c760eccb8ff",
       "IPY_MODEL_f43f4eeec1f1461c920cb6ba77c9d6c5"
      ],
      "layout": "IPY_MODEL_0685bc3738cc4e849e605f88018c6347"
     }
    },
    "c94a0509ec9d4e6f834a8c1c6c0a5c2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd26db76486046159e0dbcb03590b858": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfbf0b6eb8754f57a0e5cf88299fb6a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a47e7995c3034fcfac35736115df1273",
       "IPY_MODEL_a37ac19f555f41bd97c92af42597ef35",
       "IPY_MODEL_1b3908a006ee4717ba1ed93b259e581e"
      ],
      "layout": "IPY_MODEL_5a2eee34cc44494a905c23f8dc16ad0b"
     }
    },
    "d021b33129a34c1a8b17a9b795b470ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d73f27394d234f5b994b336aed3dbb0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d77668303f8a45a5b2d7ca68f45503d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8aed2cfe5ead4b3c86f566bb0bf58601",
      "placeholder": "​",
      "style": "IPY_MODEL_9f2340c0a3574d9e81c46f41294b4942",
      "value": ""
     }
    },
    "dcab59517bbb48738932642301ad09d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83b961d96aed41b8b7f56b915c4bae32",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a253bc5349fb430c832598353d4efb57",
      "value": 1648877
     }
    },
    "f1e222d11c5142feb554b3f7ae51d6a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f43f4eeec1f1461c920cb6ba77c9d6c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd26db76486046159e0dbcb03590b858",
      "placeholder": "​",
      "style": "IPY_MODEL_8a272efbc03d4b7bae0bd2caa04c2470",
      "value": " 9913344/? [00:00&lt;00:00, 17203788.00it/s]"
     }
    },
    "f98b352cee544ae4b7e2bdb3fdb8b07d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbf3b6a5c5a143c5bd7d14a6b4492f6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
